{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow INFO and WARNING\n",
    "os.environ['ABSL_LOG_LEVEL'] = '3'        # Suppress absl logging\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      print(\"Found GPU:\", gpu)\n",
    "    print(f\"Avail GPU Num: {len(gpus)}\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "else:\n",
    "  print(\"No GPU found, using CPU...\")\n",
    "\n",
    "\n",
    "def load_data(image_dir, mask_dir, image_size=(128, 128)):\n",
    "    if not os.path.exists(image_dir):\n",
    "        raise FileNotFoundError(f\"Image directory not found: {image_dir}\")\n",
    "    if not os.path.exists(mask_dir):\n",
    "        raise FileNotFoundError(f\"Mask directory not found: {mask_dir}\")\n",
    "\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    # List all image filenames and sort them\n",
    "    image_filenames = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
    "    mask_filenames = sorted([f for f in os.listdir(mask_dir) if f.endswith('.png')])\n",
    "\n",
    "    for filename in image_filenames:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        mask_filename = filename.replace('.jpg', '.png')  # Replace extension for masks\n",
    "        mask_path = os.path.join(mask_dir, mask_filename)\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Image file not found: {img_path}\")\n",
    "            continue\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Mask file not found: {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        img = load_img(img_path, color_mode='rgb', target_size=image_size)\n",
    "        mask = load_img(mask_path, color_mode='grayscale', target_size=image_size)\n",
    "\n",
    "        img = img_to_array(img)\n",
    "        mask = img_to_array(mask)\n",
    "\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Correct paths according to your setup\n",
    "image_dir = \"/home/starlink/bxhu/sic-unet-sat/Dataset/Image\"\n",
    "mask_dir = \"/home/starlink/bxhu/sic-unet-sat/Dataset/Mask\"\n",
    "\n",
    "# Load the dataset\n",
    "images, masks = load_data(image_dir, mask_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82272b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840098d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335fc266",
   "metadata": {},
   "source": [
    "## Normalizing and Visualizing a sample image & mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(images[0]), np.max(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0] = images[0].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47691f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image = (images[0] - 6.0) / (255.0 - 6.0)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.clip(normalized_image, 0, 1))\n",
    "plt.axis('off')\n",
    "plt.title(\"Image\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.clip(masks[0], 0, 1))\n",
    "plt.axis('off')\n",
    "plt.title(\"Mask\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec107c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize images and masks\n",
    "images = images / 255.0\n",
    "masks = masks / 255.0\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc39103",
   "metadata": {},
   "source": [
    "## U-Net Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bed12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "\n",
    "def unet_model(input_size=(128, 128, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder (downsampling path)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Decoder (upsampling path)\n",
    "    u6 = UpSampling2D((2, 2))(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = UpSampling2D((2, 2))(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = UpSampling2D((2, 2))(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = UpSampling2D((2, 2))(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model()\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec6d96",
   "metadata": {},
   "source": [
    "## Plotting Model's Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759d81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(X_val)\n",
    "predictions = model.predict(X_val, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7e218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_image_groundtruth_prediction(image, groundtruth, prediction, index):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image[index])\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Ground Truth\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(groundtruth[index].squeeze(),cmap='gray')  \n",
    "    plt.axis('off')\n",
    "    plt.title('Ground Truth')\n",
    "\n",
    "    # Prediction\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(prediction[index].squeeze(),cmap='gray')  \n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Sample\n",
    "plot_image_groundtruth_prediction(X_val, y_val, predictions, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8d5b1",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator \n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb782c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=1),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b18028",
   "metadata": {},
   "source": [
    "## Predict with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_augmentation(model, datagen, X_val, y_val, index=0):\n",
    "    # Create a batch generator for the validation data\n",
    "    augmented_generator = datagen.flow(X_val, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Get augmented image and mask\n",
    "    augmented_image = next(augmented_generator)[0]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(np.expand_dims(augmented_image, axis=0))\n",
    "    \n",
    "    return augmented_image, y_val[index], predictions[0]\n",
    "\n",
    "# Example usage\n",
    "augmented_image, groundtruth, prediction = predict_with_augmentation(model, datagen, X_val, y_val, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_groundtruth_prediction(image, groundtruth, prediction):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Ground Truth\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(groundtruth.squeeze(), cmap='gray')  \n",
    "    plt.title('Ground Truth')\n",
    "\n",
    "    # Prediction\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(prediction.squeeze(), cmap='gray')  \n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_image_groundtruth_prediction(augmented_image, groundtruth, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image_groundtruth_prediction(images, groundtruths, predictions, index):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(images[index])\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Ground Truth\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(groundtruths[index].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Ground Truth')\n",
    "\n",
    "    # Prediction\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predictions[index].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_image_groundtruth_prediction(X_val, y_val, predictions, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# --- Best Practice: Ensure the output directory exists ---\n",
    "output_dir = './output/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def plot_image_groundtruth_prediction(images, groundtruths, predictions, index):\n",
    "    # Create a new figure for each plot\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(images[index])\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "\n",
    "    # Ground Truth\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(groundtruths[index].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Ground Truth')\n",
    "\n",
    "    # Prediction\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predictions[index].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction')\n",
    "    \n",
    "    # Save the figure to a file\n",
    "    plt.savefig(os.path.join(output_dir, f\"cmp-{index}.png\"))\n",
    "    \n",
    "    # --- IMPORTANT: Close the figure to free up memory ---\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Your existing loop remains the same ---\n",
    "for idx in range(len(X_val)):\n",
    "    plot_image_groundtruth_prediction(X_val, y_val, predictions, index=idx)\n",
    "\n",
    "print(\"All images have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
